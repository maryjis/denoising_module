{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель классификации шум/ чистый звук"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from early_stopping import EarlyStopping \n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classification_dataset(dir_path):\n",
    "    dir_path =\"train\"\n",
    "    clean_path =\"clean\"\n",
    "    noisy_path =\"noisy\"\n",
    "    train_packages =os.listdir(os.path.join(dir_path, clean_path))\n",
    "    train =[]\n",
    "    for train_package in train_packages:\n",
    "        clean_package =os.path.join(dir_path,clean_path,train_package)\n",
    "        mel_files =os.listdir(clean_package)\n",
    "        for mel_file in mel_files:\n",
    "            mel_clean =os.path.join(clean_package,mel_file)\n",
    "            mel_noisy =os.path.join(dir_path, noisy_path,train_package,mel_file)\n",
    "            train.append({\"path\" :mel_clean, \"label\": 0})\n",
    "            train.append({\"path\" :mel_noisy, \"label\": 1})\n",
    "    return pd.DataFrame.from_dict(train)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset =create_classification_dataset(\"train\")\n",
    "# train_dataset =train_dataset.sample(frac=1)\n",
    "# train_dataset=train_dataset.reset_index(drop=True)\n",
    "# train_dataset.to_csv(\"train_dataset.csv\")\n",
    "# val_dataset =create_classification_dataset(\"val\")\n",
    "# val_dataset =val_dataset.sample(frac=1)\n",
    "# val_dataset=val_dataset.reset_index(drop=True)\n",
    "# val_dataset.to_csv(\"val_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_numpy(numpy_array):\n",
    "        numpy_array =(numpy_array -numpy_array.min())/ (numpy_array.max()- numpy_array.min()) *255\n",
    "        img =Image.fromarray(numpy_array.astype(np.uint8))\n",
    "        img = img.convert(\"RGB\")\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenoisingClassificationDataset(Dataset):    \n",
    "    \"\"\"Sound denoising dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, train_path, transform=None):\n",
    "        self.train_path = train_path\n",
    "        self.data =pd.read_csv(self.train_path)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data_row =self.data.iloc[idx]\n",
    "        path =data_row[\"path\"]\n",
    "        label= data_row[\"label\"]\n",
    "        array =np.load(path)\n",
    "        if(self.transform):\n",
    "            img = self.transform(array)\n",
    "        return img,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation_simple(image_size):\n",
    "    return torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Lambda(preprocess_numpy),\n",
    "        torchvision.transforms.Resize(image_size),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(\n",
    "            [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "\n",
    "def augmentation_standart(image_size):\n",
    "    return torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Lambda(preprocess_numpy),\n",
    "        torchvision.transforms.Resize(image_size),\n",
    "        torchvision.transforms.RandomHorizontalFlip(),\n",
    "        torchvision.transforms.ColorJitter(0.3,0.3,0,0),\n",
    "        torchvision.transforms.RandomVerticalFlip(),\n",
    "        torchvision.transforms.RandomRotation(10),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(\n",
    "            [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=DenoisingClassificationDataset(\"train_dataset.csv\",augmentation_standart((756,80)))\n",
    "val_data=DenoisingClassificationDataset(\"val_dataset.csv\",augmentation_simple((756,80)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader =DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader =DataLoader(val_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs =50\n",
    "learning_rate =0.001\n",
    "early_stopping =EarlyStopping(checkpoint_name=\"classifier_noise.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, param in enumerate(model.named_parameters()):\n",
    "            layer = param[0].split('.')[0]\n",
    "            if (layer == 'layer4'):\n",
    "                param[1].requires_grad = True\n",
    "            else:\n",
    "                param[1].requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ftrs = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(num_ftrs, 1)\n",
    "model=model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,\n",
    "                             weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 10, gamma=0.1, last_epoch=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(model,criterion, val_loader):\n",
    "    epoch_loss =0\n",
    "    epoch_accuracy =0\n",
    "    count =0\n",
    "    total_number =0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            model.eval()\n",
    "            images = images.cuda()\n",
    "            labels = labels.type(torch.FloatTensor).cuda()\n",
    "\n",
    "            # ===================forward=====================\n",
    "            output = model(images)\n",
    "            output = output.squeeze()\n",
    "            loss = criterion(output, labels)\n",
    "            epoch_loss+=loss.cpu().detach().numpy()\n",
    "            preds = np.where(output.cpu().detach().numpy() > 0.5, 1, 0)\n",
    "            accuracy = np.sum(preds == labels.cpu().detach().numpy())\n",
    "            total_number +=images.shape[0]\n",
    "            epoch_accuracy +=accuracy\n",
    "         \n",
    "\n",
    "        # ===================log========================\n",
    "        print('epoch val loss:{:.4f}, accuracy:{:.4f}'.format(epoch_loss/total_number, epoch_accuracy/total_number))\n",
    "    return epoch_loss/total_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/50 LR: [0.001]\n",
      "epoch train loss:0.0024, accuracy:0.9407\n",
      "epoch val loss:0.0022, accuracy:0.9600\n",
      "Epoch: 1/50 LR: [0.001]\n",
      "epoch train loss:0.0018, accuracy:0.9570\n",
      "epoch val loss:0.0013, accuracy:0.9709\n",
      "Epoch: 2/50 LR: [0.001]\n",
      "epoch train loss:0.0015, accuracy:0.9628\n",
      "epoch val loss:0.0013, accuracy:0.9709\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch: 3/50 LR: [0.001]\n",
      "epoch train loss:0.0014, accuracy:0.9647\n",
      "epoch val loss:0.0011, accuracy:0.9756\n",
      "Epoch: 4/50 LR: [0.001]\n",
      "epoch train loss:0.0014, accuracy:0.9659\n",
      "epoch val loss:0.0013, accuracy:0.9654\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch: 5/50 LR: [0.001]\n",
      "epoch train loss:0.0013, accuracy:0.9689\n",
      "epoch val loss:0.0011, accuracy:0.9772\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch: 6/50 LR: [0.001]\n",
      "epoch train loss:0.0013, accuracy:0.9697\n",
      "epoch val loss:0.0016, accuracy:0.9677\n",
      "EarlyStopping counter: 3 out of 7\n",
      "Epoch: 7/50 LR: [0.001]\n",
      "epoch train loss:0.0013, accuracy:0.9702\n",
      "epoch val loss:0.0012, accuracy:0.9766\n",
      "EarlyStopping counter: 4 out of 7\n",
      "Epoch: 8/50 LR: [0.001]\n",
      "epoch train loss:0.0011, accuracy:0.9730\n",
      "epoch val loss:0.0017, accuracy:0.9676\n",
      "EarlyStopping counter: 5 out of 7\n",
      "Epoch: 9/50 LR: [0.001]\n",
      "epoch train loss:0.0012, accuracy:0.9730\n",
      "epoch val loss:0.0012, accuracy:0.9635\n",
      "EarlyStopping counter: 6 out of 7\n",
      "Epoch: 10/50 LR: [0.0001]\n",
      "epoch train loss:0.0010, accuracy:0.9780\n",
      "epoch val loss:0.0008, accuracy:0.9830\n",
      "Epoch: 11/50 LR: [0.0001]\n",
      "epoch train loss:0.0009, accuracy:0.9793\n",
      "epoch val loss:0.0008, accuracy:0.9817\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch: 12/50 LR: [0.0001]\n",
      "epoch train loss:0.0008, accuracy:0.9799\n",
      "epoch val loss:0.0008, accuracy:0.9837\n",
      "Epoch: 13/50 LR: [0.0001]\n",
      "epoch train loss:0.0008, accuracy:0.9815\n",
      "epoch val loss:0.0008, accuracy:0.9815\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch: 14/50 LR: [0.0001]\n",
      "epoch train loss:0.0008, accuracy:0.9814\n",
      "epoch val loss:0.0007, accuracy:0.9839\n",
      "Epoch: 15/50 LR: [0.0001]\n",
      "epoch train loss:0.0008, accuracy:0.9822\n",
      "epoch val loss:0.0008, accuracy:0.9844\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch: 16/50 LR: [0.0001]\n",
      "epoch train loss:0.0008, accuracy:0.9820\n",
      "epoch val loss:0.0008, accuracy:0.9841\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch: 17/50 LR: [0.0001]\n",
      "epoch train loss:0.0008, accuracy:0.9822\n",
      "epoch val loss:0.0007, accuracy:0.9838\n",
      "Epoch: 18/50 LR: [0.0001]\n",
      "epoch train loss:0.0008, accuracy:0.9827\n",
      "epoch val loss:0.0007, accuracy:0.9836\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch: 19/50 LR: [0.0001]\n",
      "epoch train loss:0.0008, accuracy:0.9838\n",
      "epoch val loss:0.0007, accuracy:0.9831\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch: 20/50 LR: [1.0000000000000003e-05]\n",
      "epoch train loss:0.0007, accuracy:0.9820\n",
      "epoch val loss:0.0007, accuracy:0.9844\n",
      "Epoch: 21/50 LR: [1.0000000000000003e-05]\n",
      "epoch train loss:0.0007, accuracy:0.9838\n",
      "epoch val loss:0.0007, accuracy:0.9850\n",
      "Epoch: 22/50 LR: [1.0000000000000003e-05]\n",
      "epoch train loss:0.0007, accuracy:0.9836\n",
      "epoch val loss:0.0007, accuracy:0.9851\n",
      "Epoch: 23/50 LR: [1.0000000000000003e-05]\n",
      "epoch train loss:0.0007, accuracy:0.9842\n",
      "epoch val loss:0.0007, accuracy:0.9845\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch: 24/50 LR: [1.0000000000000003e-05]\n",
      "epoch train loss:0.0007, accuracy:0.9838\n",
      "epoch val loss:0.0007, accuracy:0.9842\n",
      "Epoch: 25/50 LR: [1.0000000000000003e-05]\n",
      "epoch train loss:0.0007, accuracy:0.9831\n",
      "epoch val loss:0.0007, accuracy:0.9842\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch: 26/50 LR: [1.0000000000000003e-05]\n",
      "epoch train loss:0.0007, accuracy:0.9845\n",
      "epoch val loss:0.0007, accuracy:0.9851\n",
      "Epoch: 27/50 LR: [1.0000000000000003e-05]\n",
      "epoch train loss:0.0007, accuracy:0.9835\n",
      "epoch val loss:0.0006, accuracy:0.9852\n",
      "Epoch: 28/50 LR: [1.0000000000000003e-05]\n",
      "epoch train loss:0.0006, accuracy:0.9855\n",
      "epoch val loss:0.0006, accuracy:0.9854\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch: 29/50 LR: [1.0000000000000003e-05]\n",
      "epoch train loss:0.0007, accuracy:0.9853\n",
      "epoch val loss:0.0006, accuracy:0.9853\n",
      "Epoch: 30/50 LR: [1.0000000000000002e-06]\n",
      "epoch train loss:0.0007, accuracy:0.9841\n",
      "epoch val loss:0.0006, accuracy:0.9855\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch: 31/50 LR: [1.0000000000000002e-06]\n",
      "epoch train loss:0.0007, accuracy:0.9843\n",
      "epoch val loss:0.0006, accuracy:0.9852\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch: 32/50 LR: [1.0000000000000002e-06]\n",
      "epoch train loss:0.0006, accuracy:0.9852\n",
      "epoch val loss:0.0007, accuracy:0.9852\n",
      "EarlyStopping counter: 3 out of 7\n",
      "Epoch: 33/50 LR: [1.0000000000000002e-06]\n",
      "epoch train loss:0.0007, accuracy:0.9842\n",
      "epoch val loss:0.0007, accuracy:0.9850\n",
      "EarlyStopping counter: 4 out of 7\n",
      "Epoch: 34/50 LR: [1.0000000000000002e-06]\n",
      "epoch train loss:0.0007, accuracy:0.9841\n",
      "epoch val loss:0.0006, accuracy:0.9854\n",
      "EarlyStopping counter: 5 out of 7\n",
      "Epoch: 35/50 LR: [1.0000000000000002e-06]\n",
      "epoch train loss:0.0007, accuracy:0.9850\n",
      "epoch val loss:0.0006, accuracy:0.9852\n",
      "EarlyStopping counter: 6 out of 7\n",
      "Epoch: 36/50 LR: [1.0000000000000002e-06]\n",
      "epoch train loss:0.0007, accuracy:0.9850\n",
      "epoch val loss:0.0007, accuracy:0.9853\n",
      "EarlyStopping counter: 7 out of 7\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(\"Epoch: {}/{}\".format(epoch, num_epochs), 'LR:', scheduler.get_lr())\n",
    "    epoch_train_loss =0\n",
    "    epoch_accuracy =0\n",
    "    model.train()\n",
    "    total_number =0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.cuda()\n",
    "        labels = labels.type(torch.FloatTensor).cuda()\n",
    "#         print(images.shape,labels.shape)\n",
    "        # ===================forward=====================\n",
    "        output = model(images)\n",
    "        output = output.squeeze()\n",
    "        loss = criterion(output, labels)\n",
    "        epoch_train_loss+=loss.cpu().detach().numpy()\n",
    "\n",
    "        preds = np.where(output.cpu().detach().numpy() > 0.5, 1, 0)\n",
    "        accuracy = np.sum(preds == labels.cpu().detach().numpy())\n",
    "        total_number +=images.shape[0]\n",
    "        epoch_accuracy +=accuracy\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # ===================log========================\n",
    "    print('epoch train loss:{:.4f}, accuracy:{:.4f}'.format(epoch_train_loss/total_number, epoch_accuracy/total_number))\n",
    "    epoch_loss=cross_validation(model,criterion, val_loader)\n",
    "    early_stopping(epoch_loss, model)\n",
    "    scheduler.step()\n",
    "    \n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
